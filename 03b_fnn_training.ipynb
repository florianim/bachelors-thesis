{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from PriceFNN import PriceFNN\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from shap_flow_util import read_csv_between\n",
    "import datetime\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v5'\n",
    "date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "periods = [('2015-01-08', '2021-09-30'),\n",
    "            ('2021-10-01', '2023-12-31'),\n",
    "            ('2015-01-08', '2023-12-31')]\n",
    "\n",
    "for start_date, end_date in periods:\n",
    "    model_name = 'pytorch_start_{}_end_{}'.format(start_date, end_date)\n",
    "    X = read_csv_between('./data/{}/X_full.csv'.format(version), start_date, end_date)\n",
    "    y = read_csv_between('./data/{}/y_full.csv'.format(version), start_date, end_date)\n",
    "\n",
    "    block_size = \"4D\"\n",
    "\n",
    "    masker = [pd.Series(g.index) for n, g in X.groupby(pd.Grouper(freq=block_size))]\n",
    "    train_mask, test_mask = train_test_split(\n",
    "        masker, test_size=0.2, random_state=42)\n",
    "    # split training data further into training and validation:\n",
    "    train_mask, val_mask = train_test_split(train_mask, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train = X.loc[pd.concat(train_mask)]\n",
    "    X_val = X.loc[pd.concat(val_mask)]\n",
    "    X_test = X.loc[pd.concat(test_mask)]\n",
    "\n",
    "    y_train = y.loc[pd.concat(train_mask)]\n",
    "    y_val = y.loc[pd.concat(val_mask)]\n",
    "    y_test = y.loc[pd.concat(test_mask)]\n",
    "\n",
    "    X_train.to_csv('./data/{}/X_train_{}.csv'.format(version, model_name), sep=',', index=True)\n",
    "    X_val.to_csv('./data/{}/X_val_{}.csv'.format(version, model_name), sep=',', index=True)\n",
    "    X_test.to_csv('./data/{}/X_test_{}.csv'.format(version, model_name), sep=',', index=True)\n",
    "    y_train.to_csv('./data/{}/y_train_{}.csv'.format(version, model_name), sep=',', index=True)\n",
    "    y_val.to_csv('./data/{}/y_val_{}.csv'.format(version, model_name), sep=',', index=True)\n",
    "    y_test.to_csv('./data/{}/y_test_{}.csv'.format(version, model_name), sep=',', index=True)\n",
    "\n",
    "    # scale inputs\n",
    "    X_scaler = MinMaxScaler()\n",
    "    y_scaler = MinMaxScaler()\n",
    "\n",
    "    X_col = X_train.columns\n",
    "    X_train[X_col] = X_scaler.fit_transform(X_train[X_col])\n",
    "    X_test[X_col] = X_scaler.transform(X_test[X_col])\n",
    "    X_val[X_col] = X_scaler.transform(X_val[X_col])\n",
    "\n",
    "    y_col = y_train.columns\n",
    "    y_train = y_scaler.fit_transform(y_train[y_col])\n",
    "    y_test = y_scaler.transform(y_test[y_col])\n",
    "    y_val = y_scaler.transform(y_val[y_col])\n",
    "\n",
    "    with open('./credit_flow/{}/X_scaler_{}.pkl'.format(version, model_name), 'wb') as file:\n",
    "        dill.dump(X_scaler, file)\n",
    "    with open('./credit_flow/{}/y_scaler_{}.pkl'.format(version, model_name), 'wb') as file:\n",
    "        dill.dump(y_scaler, file)\n",
    "\n",
    "    inputs = torch.tensor(X_train[X_col].values, dtype=torch.float32)\n",
    "    labels = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "    dataset = TensorDataset(inputs, labels)\n",
    "    dataloader = DataLoader(dataset, num_workers=2, batch_size=128, shuffle=True)\n",
    "\n",
    "    inputs_val = torch.tensor(X_val[X_col].values, dtype=torch.float32)\n",
    "    labels_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "    dataset_val = TensorDataset(inputs_val, labels_val)\n",
    "    dataloader_val = DataLoader(dataset_val, num_workers=2, batch_size=64)\n",
    "\n",
    "    # --------------------------------\n",
    "\n",
    "    hidden_layer_sizes = [(15, 15),\n",
    "                     (10, 15),\n",
    "                     (30, 15),\n",
    "                     (10, 10),\n",
    "                     (10, 5),\n",
    "                     (15, 10),\n",
    "                     (15, 5)]\n",
    "    for l1, l2 in hidden_layer_sizes:\n",
    "        modelname = \"FNN\"\n",
    "        logger = TensorBoardLogger(\"model_logs\", name='{}'.format(modelname))\n",
    "        config = {\n",
    "                \"input_size\": len(X.columns), # automatically set to number of features\n",
    "                \"l1_size\": l1, \n",
    "                \"l2_size\": l2,\n",
    "                \"output_size\": 1,\n",
    "                \"learning_rate\": 0.001,\n",
    "                \"do\": 0 # no dropout\n",
    "        }\n",
    "        model = PriceFNN(config)\n",
    "\n",
    "        early_stop_callback = pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=30, mode=\"min\")\n",
    "        trainer = pl.Trainer(max_epochs=700, \n",
    "                        callbacks=[early_stop_callback], \n",
    "                        logger=logger, \n",
    "                        enable_progress_bar=True)\n",
    "\n",
    "        tuner = pl.tuner.Tuner(trainer)\n",
    "        lr_finder = tuner.lr_find(model=model, \n",
    "                                train_dataloaders=dataloader, \n",
    "                                val_dataloaders=dataloader_val)\n",
    "\n",
    "        suggested_lr = lr_finder.suggestion()\n",
    "        print(\"Suggested learning_rate={}\".format(suggested_lr))\n",
    "        model.learning_rate = suggested_lr\n",
    "\n",
    "        # fix progress bar: https://github.com/Lightning-AI/pytorch-lightning/issues/15283\n",
    "        trainer.fit(model, dataloader, dataloader_val)\n",
    "        torch.save(model.state_dict(), \"./models/{}/pytorch/model_{}_l1_{}_l2_{}.pkl\".format(version, model_name, l1, l2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shapley-flow",
   "language": "python",
   "name": "shapley-flow"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
